[
  {
    "text": "Nutrition Based Analysis Using Machine Learning Model",
    "styles_used": [
      {
        "font": "CMBX12",
        "size": 18,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 54,
      "y": 111,
      "width": 488,
      "height": 17
    },
    "bbox": [
      54,
      111,
      542,
      128
    ],
    "page_number": 1,
    "lines": 1,
    "index": 1,
    "is_title": true
  },
  {
    "text": "Sahitya SinghShikhar SrivastavaHarshit Yadav",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 90,
      "y": 188,
      "width": 69,
      "height": 10
    },
    "bbox": [
      90,
      188,
      159,
      198
    ],
    "page_number": 1,
    "lines": 1,
    "index": 2
  },
  {
    "text": "School of Computer Science and Artificial Intelligence (SCAI) Vellore Institute of Technology Bhopal, India sahitya.23bai10570@vitbhopal.ac.inshikhar.23bai10613@vitbhopal.ac.inharshit.23bai10556@vitbhopal.ac.in",
    "styles_used": [
      {
        "font": "CMTI10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 49,
      "y": 200,
      "width": 151,
      "height": 58
    },
    "bbox": [
      49,
      200,
      200,
      258
    ],
    "page_number": 1,
    "lines": 5,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 5,
      "original_styles_count": 5
    },
    "consolidation_info": {
      "original_lines_count": 5,
      "original_spans_count": 5,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 3
  },
  {
    "text": "Naman GuptaAarya NemaAnshu Kumar",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 89,
      "y": 278,
      "width": 72,
      "height": 10
    },
    "bbox": [
      89,
      278,
      161,
      288
    ],
    "page_number": 1,
    "lines": 1,
    "index": 4
  },
  {
    "text": "School of Computer Science and Artificial Intelligence (SCAI) Vellore Institute of Technology Bhopal, India naman.23bai10625@vitbhopal.ac.inaarya.23bai10786@vitbhopal.ac.inanshu.23bai10519@vitbhopal.ac.in",
    "styles_used": [
      {
        "font": "CMTI10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 49,
      "y": 290,
      "width": 151,
      "height": 58
    },
    "bbox": [
      49,
      290,
      200,
      348
    ],
    "page_number": 1,
    "lines": 5,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 5,
      "original_styles_count": 5
    },
    "consolidation_info": {
      "original_lines_count": 5,
      "original_spans_count": 5,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 5
  },
  {
    "text": "I.Abstract",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 128,
      "y": 381,
      "width": 9,
      "height": 12
    },
    "bbox": [
      128,
      381,
      137,
      393
    ],
    "page_number": 1,
    "lines": 1,
    "index": 6
  },
  {
    "text": "significantly influence overall well-being, physical devel- opment, and the prevention of illnesses. Nutrition plays The increasing incidence of non-communicable diseasesa crucial role by clarifying how diet impacts health and (NCDs) due to inappropriate dietary practices has fu-quality of life. As noted by Melaku et al. [3], most dis- eled the necessity for sophisticated instruments in nutri-eases are not inherited but are primarily the result of poor tional analysis and intervention. This paper proposes adietary patterns, leading to substantial global healthcare machine learning-based method to assess the nutritionalexpenditures. Nutritional science provides crucial insights value of packaged food items. Based on data from Open-into the root causes of diseases and enhances our ability FoodFacts, we created and compared various classificationto develop effective preventive measures. It also plays a models\u2014Random Forest, Logistic Regression, and differ-vital role in examining how diseases are distributed across ent Support Vector Machine (SVM) models\u2014to classifypopulations. Popkin et al. [4] report significant shifts in health ratings (A to E) according to ingredient makeupglobal dietary habits, which are closely linked to changes and nutrition labels. Of the models tested, the Randomin disease patterns.These ongoing developments high- Forest classifier had the best accuracy of around 89%,light the essential role of nutrition in tackling widespread showing its effectiveness in dealing with class imbalancehealth issues such as obesity, diabetes, and cardiovascular and intricate nutritional data. The system developed fromdiseases [5]. this is an enabling tool for individualized nutrition coun- Beyond its role in preventing disease, nutrition is also seling and consumer education. Directions for the future essential in managing and treating a wide range of health involve incorporating this model into mobile systems to conditions [6].As highlighted in a 2020 report by the enable real-time analysis of foods and improved decision- American Diabetes Association, medical nutrition ther- making. apy\u2014an integral aspect of managing diseases such as dia-",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 386,
      "width": 510,
      "height": 255
    },
    "bbox": [
      43,
      386,
      553,
      641
    ],
    "page_number": 1,
    "index": 7
  },
  {
    "text": "II.Introductionbetes\u2014is grounded in well-established nutritional science",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 114,
      "y": 646,
      "width": 14,
      "height": 12
    },
    "bbox": [
      114,
      646,
      128,
      658
    ],
    "page_number": 1,
    "lines": 1,
    "index": 8
  },
  {
    "text": "principles [7]. Furthermore, the field of nutrition is ad- vancing swiftly with the integration of genomics and the Nutrition science explores the intricate relationship be- emergence of personalized nutrition. This innovative ap- tween dietary intake, health outcomes, and disease preven- proach customizes dietary guidance according to an in- tion [1].Nutrition is fundamentally linked to both physio-dividual\u2019s genetic makeup [8], holding great promise for logical and biochemical functions, as it explains how food transforming disease prevention strategies and improving components supply energy or contribute to the formation overall health outcomes. of body tissues [2].The processes are vital to life and affect overall health, physical development, and the pre-While traditional methods rely heavily on clinical and observational studies, modern advancements in artificial vention of disease.These mechanisms are vital for life and 1",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 655,
      "width": 510,
      "height": 147
    },
    "bbox": [
      43,
      655,
      553,
      802
    ],
    "page_number": 1,
    "index": 9
  },
  {
    "text": "intelligence (AI), particularly machine learning (ML), of-tor Machine). These will than analyze and sort the food fer transformative capabilities. These technologies enableproduct based on the ingredients provided by the company the processing of vast nutritional datasets, revealing hid-itself and these are further broken into nutritional value den patterns and supporting data-driven dietary recom-for each ingredient 100g of product. It will then classify mendations [9, 10]. Personalization of diet to predictivethe products it scanned and give them a health label from prevention models of disease, the potential uses of AI inA to E, A being the healthiest and E being the unhealthi- nutrition are diverse and far-reaching. Integration of AIest. We Created similar models with the same data to see applications in nutrition introduces technological advance-which one performs better in the packaged food classifica- ment that shifts the paradigm of dietary interventions [11].tion based on various parameters AI approaches have much potential in this era of data to transform the way we understand, track, and optimize nu-",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 75,
      "width": 250,
      "height": 129
    },
    "bbox": [
      43,
      75,
      293,
      204
    ],
    "page_number": 2,
    "index": 10
  },
  {
    "text": "III.Frameworks",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 374,
      "y": 192,
      "width": 19,
      "height": 12
    },
    "bbox": [
      374,
      192,
      393,
      204
    ],
    "page_number": 2,
    "lines": 1,
    "index": 11
  },
  {
    "text": "tritional outcomes. The study was started by the installation of a few",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 206,
      "width": 510,
      "height": 24
    },
    "bbox": [
      43,
      206,
      553,
      230
    ],
    "page_number": 2,
    "lines": 2,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 2,
      "original_styles_count": 2
    },
    "consolidation_info": {
      "original_lines_count": 2,
      "original_spans_count": 2,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 12
  },
  {
    "text": "A.BackgroundPython models/Libraries, as the Machine Learning model",
    "styles_used": [
      {
        "font": "CMTI12",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 231,
      "width": 12,
      "height": 11
    },
    "bbox": [
      43,
      231,
      55,
      242
    ],
    "page_number": 2,
    "lines": 1,
    "index": 13
  },
  {
    "text": "is based on Python. These models are are follows- Traditional applications like MyFitnessPal and Yuka use barcode scanning for nutritional display but lack per-A.Matplotlib [11] sonalized health assessments. Nutritional databases such as USDA and OpenFoodFacts provide valuable data but Matplotlib is a comprehensive, free, and open-source are static and do not offer health impact evaluations.plotting library for the Python programming language, While barcode scanners offer ease of use, they are of-designed to work well with NumPy and the broader SciPy stack. It provides an object-oriented API for embedding ten limited by the quality of their data sources. Machine plots into applications using general-purpose GUI toolk- learning has entered this domain with applications that its, as well as a procedural interface (pyplot) for creat- seek to classify foods as healthy or unhealthy using ingre- ing various static, animated, and interactive visualizations dients and nutrition labels. However, many systems lack transparency, personalization, and adaptability.quickly. It features extensive capabilities for generating numerous plot types including line plots, scatter plots, NutriScore differentiates itself by combining multiplebar charts, histograms, error charts, contour plots, and methodologies: it blends data retrieval, real-time scan- 3D surfaces. ning, user customization, and robust classification models, offering a more holistic view of nutrition.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 244,
      "width": 510,
      "height": 201
    },
    "bbox": [
      43,
      244,
      553,
      445
    ],
    "page_number": 2,
    "index": 14
  },
  {
    "text": "B.Scikit-Learn(sklearn) [12]",
    "styles_used": [
      {
        "font": "CMTI12",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 438,
      "width": 12,
      "height": 12
    },
    "bbox": [
      303,
      438,
      315,
      450
    ],
    "page_number": 2,
    "lines": 1,
    "index": 15
  },
  {
    "text": "1.Details",
    "styles_used": [
      {
        "font": "CMTI10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 459,
      "width": 8,
      "height": 10
    },
    "bbox": [
      43,
      459,
      51,
      469
    ],
    "page_number": 2,
    "lines": 1,
    "index": 16
  },
  {
    "text": "scikit-learn (formerly scikits.learn and also known as sklearn) is a free and open-source machine learning library for the Python programming language. It features var- ious classification, regression, and clustering algorithms including support-vector machines, random forests, gradi- ent boosting, k-means, and DBSCAN.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 463,
      "width": 250,
      "height": 70
    },
    "bbox": [
      303,
      463,
      553,
      533
    ],
    "page_number": 2,
    "lines": 6,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 6,
      "original_styles_count": 6
    },
    "consolidation_info": {
      "original_lines_count": 6,
      "original_spans_count": 6,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 17
  },
  {
    "text": "C.Numpy [13]",
    "styles_used": [
      {
        "font": "CMTI12",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 547,
      "width": 12,
      "height": 12
    },
    "bbox": [
      303,
      547,
      315,
      559
    ],
    "page_number": 2,
    "lines": 1,
    "index": 18
  },
  {
    "text": "NumPy brings the computational power of languages like C and Fortran to Python, a language much easier to learn and use. With this power comes simplicity: a solu- tion in NumPy is often clear and elegant.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 573,
      "width": 250,
      "height": 46
    },
    "bbox": [
      303,
      573,
      553,
      619
    ],
    "page_number": 2,
    "lines": 4,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 4,
      "original_styles_count": 4
    },
    "consolidation_info": {
      "original_lines_count": 4,
      "original_spans_count": 4,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 19
  },
  {
    "text": "D.Pandas [14]",
    "styles_used": [
      {
        "font": "CMTI12",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 633,
      "width": 13,
      "height": 12
    },
    "bbox": [
      303,
      633,
      316,
      645
    ],
    "page_number": 2,
    "lines": 1,
    "index": 20
  },
  {
    "text": "Pandas is a fast, powerful, flexible, and easy-to-use open-source data analysis and manipulation tool, built on top of the Python programming language.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 658,
      "width": 250,
      "height": 34
    },
    "bbox": [
      303,
      658,
      553,
      692
    ],
    "page_number": 2,
    "lines": 3,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 3,
      "original_styles_count": 3
    },
    "consolidation_info": {
      "original_lines_count": 3,
      "original_spans_count": 3,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 21
  },
  {
    "text": "IV.Methods",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 386,
      "y": 704,
      "width": 18,
      "height": 12
    },
    "bbox": [
      386,
      704,
      404,
      716
    ],
    "page_number": 2,
    "lines": 1,
    "index": 22
  },
  {
    "text": "Figure I: Feature Importance",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 100,
      "y": 722,
      "width": 136,
      "height": 9
    },
    "bbox": [
      100,
      722,
      236,
      731
    ],
    "page_number": 2,
    "lines": 1,
    "index": 23
  },
  {
    "text": "A dataset from opensource websites in the csv format Here we create a hybrid model using four various machine learning algorithms, namely logistic regression, decisionwas further refined. This database included the name of tree classifier, random forest classifier, SVM (Scalar Vec- the packaged food products, the barcode of the products, 2",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 732,
      "width": 510,
      "height": 70
    },
    "bbox": [
      43,
      732,
      553,
      802
    ],
    "page_number": 2,
    "index": 24
  },
  {
    "text": "the nutrition score ranging from A to E (A being the bestgram in the form of an .csv file(Comma-separated values and E being the worst) ,the list of the ingredients of the(CSV) is a text file format that uses commas to separate packaged food products and lastly nutrition facts of prod-values, and newlines to separate records. Label encoder uct per 100g. Another dataset listing critical intake valueswas used to transform data entries into numeric form, of nutrients such as carbs and fats for various medical con-which was imported from the sklearn library. ditions.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 75,
      "width": 250,
      "height": 69
    },
    "bbox": [
      43,
      75,
      293,
      144
    ],
    "page_number": 3,
    "lines": 6,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 6,
      "original_styles_count": 6
    },
    "consolidation_info": {
      "original_lines_count": 6,
      "original_spans_count": 6,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 25
  },
  {
    "text": "A.Algorithms",
    "styles_used": [
      {
        "font": "CMTI12",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 147,
      "width": 12,
      "height": 12
    },
    "bbox": [
      303,
      147,
      315,
      159
    ],
    "page_number": 3,
    "lines": 1,
    "index": 26
  },
  {
    "text": "This Database is then utilized to apply different Ma- chine Learning based models, Random Forest Classifica- tion, SVM(Support Vector Machine), Decision Tree Clas- sifier and Logistic Regression.Random forest Classifier is developed by utilizing an estimator value of 100, i.e., there are 100 decision trees from which the model will execute and make decisions based on majority. Class weight was kept as balanced and random state as 1. Then the Logistic Regression model was made from the same database, the iterations of the model was set to be 1000, iterations are the number of times the model is to be run to find out the best possible result, the class weight",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 172,
      "width": 250,
      "height": 148
    },
    "bbox": [
      303,
      172,
      553,
      320
    ],
    "page_number": 3,
    "lines": 12,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 12,
      "original_styles_count": 12
    },
    "consolidation_info": {
      "original_lines_count": 12,
      "original_spans_count": 12,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 27
  },
  {
    "text": "Figure II: Unrefined Dataset from OpenFoodFacts",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 50,
      "y": 314,
      "width": 236,
      "height": 9
    },
    "bbox": [
      50,
      314,
      286,
      323
    ],
    "page_number": 3,
    "lines": 1,
    "index": 28
  },
  {
    "text": "was set to be balanced and the random state was set to All this data was extracted from the Open Food Facts be 1(to avoid repetition and used to shuffle). website from the India section [?]. The data was taken from the India section of the website which was sorted by the country sorting option given on the website. The data on the website had many discrepancy, like some of the packaged food products didn\u2019t have the ingre- dients mentioned in them some didn\u2019t have nutrition la- bel, so these entries were injured and out of the 39,00,000 food products in the file around 7000 to 8000 food prod- ucts were taken into accord and converted into an excel database, containing Packaged product name, Nutri score of each product, barcode of each Food product and the ingredients of all the packaged food products, all this in- formation available on the website itself. Then the data was processed and refined, mainly deletion of some food ingredients that are not so important and only considering the food ingredients that make up most of the packaged food product.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 322,
      "width": 510,
      "height": 230
    },
    "bbox": [
      43,
      322,
      553,
      552
    ],
    "page_number": 3,
    "lines": 19,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 20,
      "original_styles_count": 20
    },
    "consolidation_info": {
      "original_lines_count": 19,
      "original_spans_count": 20,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 29
  },
  {
    "text": "Figure IV: Logistic Regression",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 357,
      "y": 583,
      "width": 143,
      "height": 9
    },
    "bbox": [
      357,
      583,
      500,
      592
    ],
    "page_number": 3,
    "lines": 1,
    "index": 30
  },
  {
    "text": "SVM with Linear Kernel: An SVM model was cre- ated with the kernel type set to \u2019linear\u2019. The class weight parameter was set to \u2019balanced\u2019, similar to the Logistic Regression model. This parameter scales the weights in- versely proportional to class frequencies in the input data. SVM with Polynomial Kernel: Another SVM model was built by setting the kernel type as \u2019poly\u2019.Besides changing class weight to \u2019balanced\u2019, degree for the poly- nomial kernel was set as 3. The degree argument specifies the order of the polynomial kernel function.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 601,
      "width": 250,
      "height": 123
    },
    "bbox": [
      303,
      601,
      553,
      724
    ],
    "page_number": 3,
    "lines": 10,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 10,
      "original_styles_count": 10
    },
    "consolidation_info": {
      "original_lines_count": 10,
      "original_spans_count": 10,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 31
  },
  {
    "text": "Figure III: Refined dataset of more than 22,000 prod- ucts",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 723,
      "width": 250,
      "height": 20
    },
    "bbox": [
      43,
      723,
      293,
      743
    ],
    "page_number": 3,
    "index": 32
  },
  {
    "text": "SVM with RBF Kernel: A third Support Vector Ma- chine (SVM) model was constructed, using the kernel type Then this database was imported into the python pro- known as \u2019rbf\u2019 (Radial Basis Function). The class weight 3",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 57,
      "y": 732,
      "width": 496,
      "height": 70
    },
    "bbox": [
      57,
      732,
      553,
      802
    ],
    "page_number": 3,
    "index": 33
  },
  {
    "text": "V.Result",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 394,
      "y": 71,
      "width": 14,
      "height": 11
    },
    "bbox": [
      394,
      71,
      408,
      82
    ],
    "page_number": 4,
    "lines": 1,
    "index": 34
  },
  {
    "text": "parameter was again set to \u2019balanced\u2019 for this specific model. The RBF kernel is commonly known as the most used kernel and can handle non-linear data.A.Logistic Regression",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 75,
      "width": 250,
      "height": 34
    },
    "bbox": [
      43,
      75,
      293,
      109
    ],
    "page_number": 4,
    "lines": 3,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 3,
      "original_styles_count": 3
    },
    "consolidation_info": {
      "original_lines_count": 3,
      "original_spans_count": 3,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 35
  },
  {
    "text": "Figure V: SVM RBF Kernel GraphFigure VII: Confusion Matrix Logistic Regression",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 87,
      "y": 345,
      "width": 162,
      "height": 9
    },
    "bbox": [
      87,
      345,
      249,
      354
    ],
    "page_number": 4,
    "lines": 1,
    "index": 36
  },
  {
    "text": "To gain deeper insights into the classification behav- Decision Tree model was also built from the same database. The random state parameter was passed as 42ior of the Logistic Regression model, a confusion matrix for reproducibility, and the class weight parameter was generated (refer figure VII). This matrix provides a passed as \u2019balanced\u2019 to balance the potential class imbal-detailed breakdown of the model\u2019s predictions, illustrat- ance in the target variableing the distribution of correct and incorrect classifications across the five designated classes (\u2019a\u2019 through \u2019e\u2019). The diagonal elements of the matrix represent the count of instances correctly classified for each respective class. The model demonstrates the highest number of true positives for class \u2019e\u2019 (859), followed by class \u2019d\u2019 (508). Class \u2019a\u2019 shows the next highest count of true positives (439), followed by class \u2019b\u2019 (332).Class \u2019c\u2019 has by far the lowest number of correctly classified instances (206). These figures indicate the model performs best on class \u2019e\u2019 but struggles significantly with identifying class \u2019c\u2019. Examination of the off-diagonal elements reveals spe- cific patterns of misclassification. The most severe confu- sion occurs where instances belonging to class \u2019c\u2019 are very frequently misclassified as class \u2019b\u2019 (337 instances). An-",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 362,
      "width": 510,
      "height": 237
    },
    "bbox": [
      43,
      362,
      553,
      599
    ],
    "page_number": 4,
    "lines": 19,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 20,
      "original_styles_count": 20
    },
    "consolidation_info": {
      "original_lines_count": 19,
      "original_spans_count": 20,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 37
  },
  {
    "text": "Figure VI: Decision Tree Graph",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 94,
      "y": 603,
      "width": 148,
      "height": 9
    },
    "bbox": [
      94,
      603,
      242,
      612
    ],
    "page_number": 4,
    "lines": 1,
    "index": 38
  },
  {
    "text": "other major error is the misclassification of true class \u2019e\u2019 instances as class \u2019d\u2019 (319 instances). Significant confusion also exists where true class \u2019d\u2019 instances are predicted as class \u2019e\u2019 (269 instances). Further substantial misclassification trends include: True class \u2019c\u2019 instances being predicted as class \u2019a\u2019 (181 instances). True class \u2019b\u2019 instances being predicted as class \u2019a\u2019 (164 instances).True class \u2019d\u2019 instances being pre- dicted as class \u2019c\u2019 (165 instances). True class \u2019e\u2019 instances being predicted as class \u2019c\u2019 (164 instances).True class \u2019a\u2019 instances being predicted as class \u2019b\u2019 (127 instances). True class \u2019e\u2019 instances being predicted as class \u2019b\u2019 (126 instances). These specific error types drastically impact 4",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 296,
      "y": 601,
      "width": 257,
      "height": 201
    },
    "bbox": [
      296,
      601,
      553,
      802
    ],
    "page_number": 4,
    "index": 39
  },
  {
    "text": "the precision and recall metrics for individual classes. Forcount of instances correctly classified for each respective example:class. The model demonstrates the highest number of true positives for class \u2019e\u2019 (869), followed by class \u2019d\u2019 (568). The extremely high misclassification of class \u2019c\u2019 (partic- Class \u2019a\u2019 shows the next highest count of true positives ularly as \u2019b\u2019 and \u2019a\u2019) results in a very poor recall for class (378), followed by class \u2019b\u2019 (355). Class \u2019c\u2019 has the low- \u2019c\u2019 and significantly diminishes the precision for classes est number of correctly classified instances (243). These \u2019b\u2019 and \u2019a\u2019.The strong bidirectional confusion between figures suggest the model is most successful in identifying classes \u2019e\u2019 and \u2019d\u2019 negatively affects the recall and preci- instances of class \u2019e\u2019 and least successful for class \u2019c\u2019. sion for both of these classes. The notable bidirectional confusion between \u2019a\u2019 and \u2019b\u2019 impacts the recall and preci-Examination of the off-diagonal elements reveals spe- sion metrics for these classes. The misclassification of \u2019d\u2019cific patterns of misclassification.The most significant and \u2019e\u2019 instances as \u2019c\u2019 lowers the recall for \u2019d\u2019 and \u2019e\u2019 whileconfusion occurs where instances belonging to class \u2019c\u2019 are also reducing the already low precision of class \u2019c\u2019. Theoverwhelmingly misclassified as class \u2019b\u2019 (393 instances). tendency for \u2019e\u2019 to be misclassified as \u2019b\u2019 further harms theAnother very prominent error is the misclassification of recall of \u2019e\u2019 and the precision of \u2019b\u2019.true class \u2019e\u2019 instances as class \u2019d\u2019 (312 instances). Fur-",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 75,
      "width": 510,
      "height": 171
    },
    "bbox": [
      43,
      75,
      553,
      246
    ],
    "page_number": 5,
    "index": 40
  },
  {
    "text": "Table I: Classification Report for Logistic Regressionthermore, a large number of true class \u2019e\u2019 instances are Modelalso predicted as class \u2019b\u2019 (253 instances).",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 251,
      "width": 250,
      "height": 20
    },
    "bbox": [
      43,
      251,
      293,
      271
    ],
    "page_number": 5,
    "lines": 2,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 2,
      "original_styles_count": 2
    },
    "consolidation_info": {
      "original_lines_count": 2,
      "original_spans_count": 2,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 41
  },
  {
    "text": "Other substantial misclassification trends include:",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 317,
      "y": 278,
      "width": 217,
      "height": 10
    },
    "bbox": [
      317,
      278,
      534,
      288
    ],
    "page_number": 5,
    "lines": 1,
    "index": 42
  },
  {
    "text": "ClassPrecisionRecallF1-ScoreSupport",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 50,
      "y": 286,
      "width": 27,
      "height": 10
    },
    "bbox": [
      50,
      286,
      77,
      296
    ],
    "page_number": 5,
    "lines": 1,
    "index": 43
  },
  {
    "text": "True class \u2019d\u2019 instances being predicted as class \u2019e\u2019 (210 0.540.720.62610 10.340.560.42592instances). True class \u2019a\u2019 instances being predicted as class 20.320.240.27861\u2019b\u2019 (203 instances).True class \u2019b\u2019 instances being pre- dicted as class \u2019a\u2019 (165 instances). True class \u2019d\u2019 instances 30.530.490.51031 40.730.580.651472being predicted as class \u2019c\u2019 (168 instances).True class",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 61,
      "y": 296,
      "width": 492,
      "height": 60
    },
    "bbox": [
      61,
      296,
      553,
      356
    ],
    "page_number": 5,
    "lines": 5,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 7,
      "original_styles_count": 7
    },
    "consolidation_info": {
      "original_lines_count": 5,
      "original_spans_count": 7,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 44
  },
  {
    "text": "Macro Average0.49 0.52 0.49 4566",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 80,
      "y": 358,
      "width": 77,
      "height": 10
    },
    "bbox": [
      80,
      358,
      157,
      368
    ],
    "page_number": 5,
    "lines": 1,
    "index": 45
  },
  {
    "text": "\u2019c\u2019 instances being predicted as class \u2019a\u2019 (142 instances).",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 356,
      "width": 250,
      "height": 10
    },
    "bbox": [
      303,
      356,
      553,
      366
    ],
    "page_number": 5,
    "lines": 1,
    "index": 46
  },
  {
    "text": "Weighted Average0.53 0.51 0.51 4566These specific error types directly impact the precision",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 72,
      "y": 370,
      "width": 92,
      "height": 10
    },
    "bbox": [
      72,
      370,
      164,
      380
    ],
    "page_number": 5,
    "lines": 1,
    "index": 47
  },
  {
    "text": "and recall metrics for individual classes. For example:",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 380,
      "width": 235,
      "height": 9
    },
    "bbox": [
      303,
      380,
      538,
      389
    ],
    "page_number": 5,
    "lines": 1,
    "index": 48
  },
  {
    "text": "B.SVM Linear KernelThe extremely high misclassification of class \u2019c\u2019 as \u2019b\u2019",
    "styles_used": [
      {
        "font": "CMTI12",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 393,
      "width": 12,
      "height": 12
    },
    "bbox": [
      43,
      393,
      55,
      405
    ],
    "page_number": 5,
    "lines": 1,
    "index": 49
  },
  {
    "text": "drastically reduces the recall for class \u2019c\u2019 and severely di- minishes the precision for class \u2019b\u2019. The significant con- fusion between classes \u2019e\u2019 and \u2019d\u2019 (in both directions, but notably \u2019e\u2019 predicted as \u2019d\u2019) impacts the recall and pre- cision for both \u2019e\u2019 and \u2019d\u2019. The frequent misclassification of \u2019e\u2019 as \u2019b\u2019 further lowers the recall for \u2019e\u2019 and precision for \u2019b\u2019. The notable bidirectional confusion between \u2019a\u2019 and \u2019b\u2019 reduces both recall and precision for these two classes. The misclassification of \u2019d\u2019 as \u2019c\u2019, and \u2019c\u2019 as \u2019a\u2019, contributes to lower recall for \u2019d\u2019 and \u2019c\u2019 respectively, and lower precision for \u2019c\u2019 and \u2019a\u2019.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 409,
      "width": 250,
      "height": 130
    },
    "bbox": [
      303,
      409,
      553,
      539
    ],
    "page_number": 5,
    "lines": 11,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 11,
      "original_styles_count": 11
    },
    "consolidation_info": {
      "original_lines_count": 11,
      "original_spans_count": 11,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 50
  },
  {
    "text": "Table II: Classification Report for SVM Linear Model",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 544,
      "width": 250,
      "height": 9
    },
    "bbox": [
      303,
      544,
      553,
      553
    ],
    "page_number": 5,
    "lines": 1,
    "index": 51
  },
  {
    "text": "ClassPrecisionRecallF1-ScoreSupport",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 311,
      "y": 568,
      "width": 26,
      "height": 10
    },
    "bbox": [
      311,
      568,
      337,
      578
    ],
    "page_number": 5,
    "lines": 1,
    "index": 52
  },
  {
    "text": "0.530.620.57610 10.280.60.38592 20.460.280.35861 30.580.550.571031 40.80.590.681472",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 321,
      "y": 580,
      "width": 5,
      "height": 58
    },
    "bbox": [
      321,
      580,
      326,
      638
    ],
    "page_number": 5,
    "lines": 5,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 5,
      "original_styles_count": 5
    },
    "consolidation_info": {
      "original_lines_count": 5,
      "original_spans_count": 5,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 53
  },
  {
    "text": "Macro Average0.53 0.53 0.51 4566",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 340,
      "y": 640,
      "width": 77,
      "height": 10
    },
    "bbox": [
      340,
      640,
      417,
      650
    ],
    "page_number": 5,
    "lines": 1,
    "index": 54
  },
  {
    "text": "Figure VIII: Confusion Matrix SVM Linear",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 68,
      "y": 645,
      "width": 200,
      "height": 9
    },
    "bbox": [
      68,
      645,
      268,
      654
    ],
    "page_number": 5,
    "lines": 1,
    "index": 55
  },
  {
    "text": "Weighted Average0.58 0.53 0.54 4566",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 332,
      "y": 652,
      "width": 92,
      "height": 9
    },
    "bbox": [
      332,
      652,
      424,
      661
    ],
    "page_number": 5,
    "lines": 1,
    "index": 56
  },
  {
    "text": "To gain deeper insights into the classification behavior of the Support Vector Machine model utilizing a Linear kernel (SVM Linear), a confusion matrix was generated (refer figure VIII). This matrix provides a detailed break- down of the model\u2019s predictions, illustrating the distribu- tion of correct and incorrect classifications across the five designated classes (\u2019a\u2019 through \u2019e\u2019). The diagonal elements of the matrix represent the 5",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 664,
      "width": 258,
      "height": 138
    },
    "bbox": [
      43,
      664,
      301,
      802
    ],
    "page_number": 5,
    "index": 57
  },
  {
    "text": "C.SVM Polynomial Kernelthe precision and recall metrics for individual classes. For",
    "styles_used": [
      {
        "font": "CMTI12",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 73,
      "width": 12,
      "height": 12
    },
    "bbox": [
      43,
      73,
      55,
      85
    ],
    "page_number": 6,
    "lines": 1,
    "index": 58
  },
  {
    "text": "example: The substantial misclassification of class \u2019e\u2019 as \u2019d\u2019 sig- nificantly reduces the recall for class \u2019e\u2019 and the precision for class \u2019d\u2019. The frequent misclassification of class \u2019c\u2019 as \u2019b\u2019 contributes to a lower recall for class \u2019c\u2019 and diminished precision for class \u2019b\u2019. The confusion where \u2019e\u2019 is predicted as \u2019c\u2019 lowers recall for \u2019e\u2019 and precision for \u2019c\u2019. Similarly, the misclassification of \u2019d\u2019 as \u2019c\u2019 affects the recall of \u2019d\u2019 and the precision of \u2019c\u2019. The confusion between \u2019a\u2019 and \u2019b\u2019 impacts the respective precision and recall values for these classes.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 87,
      "width": 250,
      "height": 135
    },
    "bbox": [
      303,
      87,
      553,
      222
    ],
    "page_number": 6,
    "lines": 11,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 11,
      "original_styles_count": 11
    },
    "consolidation_info": {
      "original_lines_count": 11,
      "original_spans_count": 11,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 59
  },
  {
    "text": "Table III: Classification Report for SVM Polynomial Model",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 226,
      "width": 250,
      "height": 20
    },
    "bbox": [
      303,
      226,
      553,
      246
    ],
    "page_number": 6,
    "lines": 2,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 2,
      "original_styles_count": 2
    },
    "consolidation_info": {
      "original_lines_count": 2,
      "original_spans_count": 2,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 60
  },
  {
    "text": "ClassPrecisionRecallF1-ScoreSupport",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 311,
      "y": 260,
      "width": 26,
      "height": 10
    },
    "bbox": [
      311,
      260,
      337,
      270
    ],
    "page_number": 6,
    "lines": 1,
    "index": 61
  },
  {
    "text": "0.610.660.63610 10.420.660.51592 20.460.4861 30.570.660.61031 40.890.480.631472",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 321,
      "y": 272,
      "width": 5,
      "height": 58
    },
    "bbox": [
      321,
      272,
      326,
      330
    ],
    "page_number": 6,
    "lines": 5,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 5,
      "original_styles_count": 5
    },
    "consolidation_info": {
      "original_lines_count": 5,
      "original_spans_count": 5,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 62
  },
  {
    "text": "Figure IX: Confusion Matrix SVM Polynomial",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 61,
      "y": 327,
      "width": 215,
      "height": 9
    },
    "bbox": [
      61,
      327,
      276,
      336
    ],
    "page_number": 6,
    "lines": 1,
    "index": 63
  },
  {
    "text": "Macro Average0.59 0.60 0.57 4566",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 340,
      "y": 332,
      "width": 77,
      "height": 10
    },
    "bbox": [
      340,
      332,
      417,
      342
    ],
    "page_number": 6,
    "lines": 1,
    "index": 64
  },
  {
    "text": "To gain deeper insights into the classification behaviorWeighted Average0.64 0.58 0.58 4566 of the Support Vector Machine model utilizing a Poly- nomial kernel (SVM Polynomial), a confusion matrix was",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 345,
      "width": 250,
      "height": 34
    },
    "bbox": [
      43,
      345,
      293,
      379
    ],
    "page_number": 6,
    "index": 65
  },
  {
    "text": "D.SVM RBF Kernel",
    "styles_used": [
      {
        "font": "CMTI12",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 367,
      "width": 13,
      "height": 12
    },
    "bbox": [
      303,
      367,
      316,
      379
    ],
    "page_number": 6,
    "lines": 1,
    "index": 66
  },
  {
    "text": "generated (refer figure IX). This matrix provides a detailed breakdown of the model\u2019s predictions, illustrating the dis- tribution of correct and incorrect classifications across the five designated classes (\u2019a\u2019 through \u2019e\u2019). The diagonal elements of the matrix represent the count of instances correctly classified for each respective class. The model demonstrates the highest number of true positives for class \u2019e\u2019 (708), followed closely by class \u2019d\u2019 (685).Class \u2019c\u2019 also shows a relatively high number of true positives (444), while classes \u2019a\u2019 and \u2019b\u2019 have slightly fewer (401 and 391, respectively). These figures suggest the model is generally most successful in identifying in- stances of classes \u2019e\u2019 and \u2019d\u2019. Examination of the off-diagonal elements reveals spe- cific patterns of misclassification.The most significant confusion is observed where instances belonging to class \u2019e\u2019 are frequently misclassified as class \u2019d\u2019 (394 instances). Another very prominent error occurs when true class \u2019c\u2019 instances are predicted as class \u2019b\u2019 (229 instances). Ad-",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 381,
      "width": 250,
      "height": 237
    },
    "bbox": [
      43,
      381,
      293,
      618
    ],
    "page_number": 6,
    "lines": 19,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 19,
      "original_styles_count": 19
    },
    "consolidation_info": {
      "original_lines_count": 19,
      "original_spans_count": 19,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 67
  },
  {
    "text": "Figure X: Confusion Matrix SVM RBF",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 339,
      "y": 616,
      "width": 179,
      "height": 9
    },
    "bbox": [
      339,
      616,
      518,
      625
    ],
    "page_number": 6,
    "lines": 1,
    "index": 68
  },
  {
    "text": "ditionally, a substantial number of true class \u2019e\u2019 instances are predicted as class \u2019c\u2019 (225 instances). To gain deeper insights into the classification behavior of the Support Vector Machine model utilizing a Radial Further notable misclassifications include: Basis Function (SVM RBF) kernel, a confusion matrix was True class \u2019d\u2019 instances being predicted as class \u2019c\u2019 (160generated (refer figure X). This matrix provides a detailed instances). True class \u2019a\u2019 instances being predicted as classbreakdown of the model\u2019s predictions, illustrating the dis- \u2019b\u2019 (148 instances). True class \u2019e\u2019 instances being predicted tribution of correct and incorrect classifications across the as \u2019b\u2019 (104 instances). True class \u2019c\u2019 instances being pre-five designated classes (\u2019a\u2019 through \u2019e\u2019). dicted as \u2019d\u2019 (103 instances).Confusion also exists be- The diagonal elements of the matrix represent the tween classes \u2019b\u2019 and \u2019c\u2019 (97 true \u2019b\u2019 instances predicted count of instances correctly classified for each respective as \u2019c\u2019) and between \u2019b\u2019 and \u2019a\u2019 (92 true \u2019b\u2019 instances pre- dicted as \u2019a\u2019). These specific error types directly impactclass.The model demonstrates the highest number of true positives for class \u2019e\u2019 (1036), followed by class \u2019d\u2019 6",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 620,
      "width": 510,
      "height": 182
    },
    "bbox": [
      43,
      620,
      553,
      802
    ],
    "page_number": 6,
    "index": 69
  },
  {
    "text": "(728).Classes \u2019a\u2019, \u2019b\u2019, and \u2019c\u2019 show progressively fewerE.Random Forest Classifier true positives (431, 405, and 388, respectively). These fig- ures generally align with the F1-scores presented in Table IV, confirming the relative success in identifying instances of classes \u2019e\u2019 and \u2019d\u2019. Examination of the off-diagonal elements reveals spe- cific patterns of misclassification. A significant confusion is observed where instances belonging to class \u2019c\u2019 are fre- quently misclassified as class \u2019b\u2019 (266 instances). Another prominent error occurs when true class \u2019e\u2019 instances are predicted as class \u2019d\u2019 (260 instances). Furthermore, no- table confusion exists between classes \u2019a\u2019 and \u2019b\u2019, with 139 true \u2019a\u2019 instances predicted as \u2019b\u2019, and 119 true \u2019b\u2019 in- stances predicted as \u2019a\u2019. Additional misclassification trends include instances of class \u2019c\u2019 being predicted as \u2019a\u2019 (95) and \u2019d\u2019 (86), instances of class \u2019d\u2019 being predicted as \u2019c\u2019 (103), and instances of class \u2019e\u2019 being predicted as \u2019b\u2019 (98).These specific er- ror types directly impact the precision and recall metrics observed for individual classes in the classification report",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 75,
      "width": 250,
      "height": 249
    },
    "bbox": [
      43,
      75,
      293,
      324
    ],
    "page_number": 7,
    "lines": 20,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 20,
      "original_styles_count": 20
    },
    "consolidation_info": {
      "original_lines_count": 20,
      "original_spans_count": 20,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 70
  },
  {
    "text": "Figure XI: Confusion Matrix Random Forest Classi-",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 321,
      "width": 250,
      "height": 9
    },
    "bbox": [
      303,
      321,
      553,
      330
    ],
    "page_number": 7,
    "lines": 1,
    "index": 71
  },
  {
    "text": "(Table IV). For example, the substantial misclassification",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 326,
      "width": 250,
      "height": 10
    },
    "bbox": [
      43,
      326,
      293,
      336
    ],
    "page_number": 7,
    "lines": 1,
    "index": 72
  },
  {
    "text": "fier",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 331,
      "width": 18,
      "height": 9
    },
    "bbox": [
      303,
      331,
      321,
      340
    ],
    "page_number": 7,
    "lines": 1,
    "index": 73
  },
  {
    "text": "of class \u2019c\u2019 as \u2019b\u2019 contributes to the reduced recall for class \u2019c\u2019 and the diminished precision for class \u2019b\u2019. Similarly,This section details the performance evaluation of a the confusion between \u2019d\u2019 and \u2019e\u2019 affects the respectiveRandom Forest classification algorithm applied to the five- precision and recall values for these classes.class dataset (\u2019a\u2019 through \u2019e\u2019). The efficacy of the model",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 338,
      "width": 250,
      "height": 46
    },
    "bbox": [
      43,
      338,
      293,
      384
    ],
    "page_number": 7,
    "lines": 4,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 4,
      "original_styles_count": 4
    },
    "consolidation_info": {
      "original_lines_count": 4,
      "original_spans_count": 4,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 74
  },
  {
    "text": "Table IV: Classification Report for SVM RBF Model",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 389,
      "width": 250,
      "height": 9
    },
    "bbox": [
      43,
      389,
      293,
      398
    ],
    "page_number": 7,
    "lines": 1,
    "index": 75
  },
  {
    "text": "is quantitatively assessed using the confusion matrix pre- sented (refer figure XI), which tabulates the prediction",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 386,
      "width": 250,
      "height": 22
    },
    "bbox": [
      303,
      386,
      553,
      408
    ],
    "page_number": 7,
    "index": 76
  },
  {
    "text": "ClassPrecisionRecallF1-ScoreSupportoutcomes against the actual class labels.",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 50,
      "y": 412,
      "width": 27,
      "height": 10
    },
    "bbox": [
      50,
      412,
      77,
      422
    ],
    "page_number": 7,
    "lines": 1,
    "index": 77
  },
  {
    "text": "0.590.710.64610 The analysis of the confusion matrix indicates a high 10.420.680.52592 degree of predictive accuracy achieved by the Random For- 20.640.450.53861est classifier. The prominent values along the main diago- 30.660.710.681031 nal (True Positives: 535 for \u2019a\u2019, 479 for \u2019b\u2019, 718 for \u2019c\u2019, 935 40.890.70.791472 for \u2019d\u2019, 1401 for \u2019e\u2019) significantly outweigh the off-diagonal",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 61,
      "y": 425,
      "width": 492,
      "height": 60
    },
    "bbox": [
      61,
      425,
      553,
      485
    ],
    "page_number": 7,
    "index": 78
  },
  {
    "text": "Macro Average0.64 0.65 0.63 4566misclassification counts.This demonstrates the ensem- Weighted Average0.69 0.65 0.66 4566",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 72,
      "y": 484,
      "width": 92,
      "height": 22
    },
    "bbox": [
      72,
      484,
      164,
      506
    ],
    "page_number": 7,
    "index": 79
  },
  {
    "text": "ble model\u2019s strong capability in discerning the underlying patterns within the dataset, resulting in a superior overall accuracy of approximately 89.1% (4068 correct predictions out of 4566 total instances). Examiningclass-specificperformancerevealsthe model\u2019s particular strengths. The Random Forest classi- fier exhibits exceptional performance for class \u2019e\u2019, achiev- ing a recall of approximately 95.2% (1401 out of 1472 in- stances correctly identified) and high precision ( 94.6%). Class \u2019d\u2019 is also classified with high accuracy (Recall 90.7%, Precision 91.0%), closely followed by class \u2019a\u2019 (Re- call 87.7%, Precision 89.2%). These results underscore the robustness of the Random Forest approach in accu- rately modeling the feature space for these classes. Despite the high overall performance, certain classifica- tion challenges persist. Similar to observations with sim- pler tree models, the Random Forest encounters difficulty in definitively separating classes \u2019b\u2019 and \u2019c\u2019. Notable mu- tual confusion remains, with 75 instances of actual class \u2019c\u2019 being misclassified as \u2019b\u2019, and 63 instances of actual class \u2019b\u2019 being misclassified as \u2019c\u2019.While the recall for both classes has improved compared to a single Decision 7",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 296,
      "y": 499,
      "width": 257,
      "height": 303
    },
    "bbox": [
      296,
      499,
      553,
      802
    ],
    "page_number": 7,
    "index": 80
  },
  {
    "text": "Tree (Class \u2019c\u2019 Recall83.4%, Class \u2019b\u2019 Recall80.9%),ing correct classifications (True Positives: 514 for \u2019a\u2019, 474 class \u2019b\u2019 continues to exhibit the lowest precision amongfor \u2019b\u2019, 675 for \u2019c\u2019, 920 for \u2019d\u2019, 1372 for \u2019e\u2019), are substan- all classes ( 78.5%). This suggests that even with the en-tially larger than the off-diagonal elements (misclassifica- semble method, the feature distinctions between \u2019b\u2019 andtions) across all classes.This indicates that the Deci- \u2019c\u2019 remain inherently challenging.Minor confusion alsosion Tree structure is reasonably well-suited for captur- persists between \u2019d\u2019 and \u2019e\u2019 (64 \u2019d\u2019 as \u2019e\u2019, 50 \u2019e\u2019 as \u2019d\u2019) anding the underlying patterns differentiating most classes \u2019a\u2019 and \u2019b\u2019 (48 \u2019a\u2019 as \u2019b\u2019, 43 \u2019b\u2019 as \u2019a\u2019).within this dataset, achieving an overall accuracy of ap- proximately 86.6% (3955 correct predictions out of 4566 The dataset\u2019s class imbalance (support ranging from total instances). 592 for \u2019b\u2019 to 1472 for \u2019e\u2019) appears well-handled by the Random Forest model.It demonstrates robustness byClass-specific analysis highlights variations in the maintaining strong performance across all classes, includ-model\u2019s effectiveness. The classifier exhibits particularly ing those with lower support, while excelling on the mosthigh efficacy for class \u2019e\u2019, correctly identifying 1372 out frequent class \u2019e\u2019.of 1472 instances (Recall 93.2%) with minimal confusion from other classes being predicted as \u2019e\u2019. Class \u2019d\u2019 also",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 75,
      "width": 510,
      "height": 171
    },
    "bbox": [
      43,
      75,
      553,
      246
    ],
    "page_number": 8,
    "index": 81
  },
  {
    "text": "Table V: Classification Report for Random Forest Modelshows robust classification (Recall89.2%), followed by",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 240,
      "width": 250,
      "height": 19
    },
    "bbox": [
      43,
      240,
      293,
      259
    ],
    "page_number": 8,
    "lines": 2,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 2,
      "original_styles_count": 2
    },
    "consolidation_info": {
      "original_lines_count": 2,
      "original_spans_count": 2,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 82
  },
  {
    "text": "class \u2019a\u2019 (Recall 84.3%). These results suggest the features",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 260,
      "width": 250,
      "height": 10
    },
    "bbox": [
      303,
      260,
      553,
      270
    ],
    "page_number": 8,
    "lines": 1,
    "index": 83
  },
  {
    "text": "ClassPrecisionRecallF1-ScoreSupport",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 50,
      "y": 274,
      "width": 27,
      "height": 10
    },
    "bbox": [
      50,
      274,
      77,
      284
    ],
    "page_number": 8,
    "lines": 1,
    "index": 84
  },
  {
    "text": "associated with classes \u2019e\u2019, \u2019d\u2019, and \u2019a\u2019 are more distinct 0.890.88610and effectively learned by the Decision Tree. 10.790.810.80592Conversely, the model encounters significant challenges 20.850.830.84861 in discriminating between classes \u2019b\u2019 and \u2019c\u2019. These two 30.91031 classes exhibit the most substantial mutual confusion: 84 40.951472 instances of actual class \u2019c\u2019 are misclassified as \u2019b\u2019, while 65",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 61,
      "y": 272,
      "width": 492,
      "height": 76
    },
    "bbox": [
      61,
      272,
      553,
      348
    ],
    "page_number": 8,
    "index": 85
  },
  {
    "text": "Macro Average0.88 0.88 0.88 4566",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 80,
      "y": 346,
      "width": 77,
      "height": 10
    },
    "bbox": [
      80,
      346,
      157,
      356
    ],
    "page_number": 8,
    "lines": 1,
    "index": 86
  },
  {
    "text": "instances of actual class \u2019b\u2019 are misclassified as \u2019c\u2019. Conse-",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 350,
      "width": 250,
      "height": 10
    },
    "bbox": [
      303,
      350,
      553,
      360
    ],
    "page_number": 8,
    "lines": 1,
    "index": 87
  },
  {
    "text": "Weighted Average0.89 0.89 0.89 4566quently, class \u2019c\u2019 registers the lowest recall ( 78.4%), and",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 72,
      "y": 358,
      "width": 92,
      "height": 10
    },
    "bbox": [
      72,
      358,
      164,
      368
    ],
    "page_number": 8,
    "lines": 1,
    "index": 88
  },
  {
    "text": "class \u2019b\u2019 shows relatively lower precision compared to other",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 374,
      "width": 250,
      "height": 10
    },
    "bbox": [
      303,
      374,
      553,
      384
    ],
    "page_number": 8,
    "lines": 1,
    "index": 89
  },
  {
    "text": "F.Decision Tree Classifier",
    "styles_used": [
      {
        "font": "CMTI12",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": true,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 381,
      "width": 11,
      "height": 12
    },
    "bbox": [
      43,
      381,
      54,
      393
    ],
    "page_number": 8,
    "lines": 1,
    "index": 90
  },
  {
    "text": "classes. This pattern suggests potential feature overlap or complexity in the decision boundaries between these spe- cific classes that the current tree structure struggles to resolve optimally.Minor confusion is also observed be- tween classes \u2019d\u2019 and \u2019e\u2019 (62 \u2019d\u2019 as \u2019e\u2019, 71 \u2019e\u2019 as \u2019d\u2019) and classes \u2019a\u2019 and \u2019b\u2019 (54 \u2019a\u2019 as \u2019b\u2019, 44 \u2019b\u2019 as \u2019a\u2019). The dataset appears to exhibit class imbalance, with support ranging from 592 instances (class \u2019b\u2019) to 1472 in- stances (class \u2019e\u2019). The Decision Tree demonstrates rea- sonable robustness, achieving good recall even for the least frequent class (\u2019b\u2019 80.1%), although its strongest perfor- mance aligns with the most frequent class (\u2019e\u2019 93.2%).",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 386,
      "width": 250,
      "height": 147
    },
    "bbox": [
      303,
      386,
      553,
      533
    ],
    "page_number": 8,
    "lines": 12,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 12,
      "original_styles_count": 12
    },
    "consolidation_info": {
      "original_lines_count": 12,
      "original_spans_count": 12,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 91
  },
  {
    "text": "Table VI: Classification Report for Decision Tree Model",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 539,
      "width": 250,
      "height": 20
    },
    "bbox": [
      303,
      539,
      553,
      559
    ],
    "page_number": 8,
    "lines": 2,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 2,
      "original_styles_count": 2
    },
    "consolidation_info": {
      "original_lines_count": 2,
      "original_spans_count": 2,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 92
  },
  {
    "text": "ClassPrecisionRecallF1-ScoreSupport",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 311,
      "y": 573,
      "width": 26,
      "height": 10
    },
    "bbox": [
      311,
      573,
      337,
      583
    ],
    "page_number": 8,
    "lines": 1,
    "index": 93
  },
  {
    "text": "0.860.840.85610 10.760.80.78592 20.80.780.79861 30.880.891031",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 321,
      "y": 585,
      "width": 5,
      "height": 46
    },
    "bbox": [
      321,
      585,
      326,
      631
    ],
    "page_number": 8,
    "lines": 4,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 4,
      "original_styles_count": 4
    },
    "consolidation_info": {
      "original_lines_count": 4,
      "original_spans_count": 4,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 94
  },
  {
    "text": "Figure XII: Confusion Matrix Decision Tree Classifier",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 629,
      "width": 250,
      "height": 9
    },
    "bbox": [
      43,
      629,
      293,
      638
    ],
    "page_number": 8,
    "lines": 1,
    "index": 95
  },
  {
    "text": "40.940.930.941472 An evaluation of a Decision Tree classification algo-",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 57,
      "y": 633,
      "width": 269,
      "height": 25
    },
    "bbox": [
      57,
      633,
      326,
      658
    ],
    "page_number": 8,
    "index": 96
  },
  {
    "text": "Macro Average0.85 0.85 0.85 4566",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 340,
      "y": 645,
      "width": 77,
      "height": 10
    },
    "bbox": [
      340,
      645,
      417,
      655
    ],
    "page_number": 8,
    "lines": 1,
    "index": 97
  },
  {
    "text": "rithm was conducted to determine its efficacy on the given",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 660,
      "width": 250,
      "height": 10
    },
    "bbox": [
      43,
      660,
      293,
      670
    ],
    "page_number": 8,
    "lines": 1,
    "index": 98
  },
  {
    "text": "Weighted Average0.87 0.87 0.87 4566",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 332,
      "y": 657,
      "width": 92,
      "height": 10
    },
    "bbox": [
      332,
      657,
      424,
      667
    ],
    "page_number": 8,
    "lines": 1,
    "index": 99
  },
  {
    "text": "dataset involving five distinct classes (labeled \u2019a\u2019 through After constructing and evaluating all the models, \u2019e\u2019).The performance is detailed in the confusion ma-the Random Forest Classifier was 89.48751642575559% trix presented (refer figure XII). This matrix visualizesaccurate,whereasthelogisticregressionwas the counts of true positive, false positive, false negative,50.45992115637319% accurate.The accuracies of var- and true negative predictions for each class.ious Support Vector Machine (SVM) models were the The analysis reveals that the Decision Tree classi-following: Linear Kernel was 53.5041611914148% accu- rate, Polynomial Kernel was 53.46035917652212% ac- fier demonstrates generally strong predictive performance. curate, and RBF Kernel was 61.65133596145422% ac- The diagonal elements of the confusion matrix, represent- 8",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 672,
      "width": 510,
      "height": 130
    },
    "bbox": [
      43,
      672,
      553,
      802
    ],
    "page_number": 8,
    "index": 100
  },
  {
    "text": "curate.Additionally, the Decision Tree Classifier wasaverages, reflecting a relatively better performance on the 86.55278142794569% accurate.more common classes.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 75,
      "width": 30,
      "height": 22
    },
    "bbox": [
      43,
      75,
      73,
      97
    ],
    "page_number": 9,
    "lines": 2,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 2,
      "original_styles_count": 2
    },
    "consolidation_info": {
      "original_lines_count": 2,
      "original_spans_count": 2,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 101
  },
  {
    "text": "Table VII: Accuracy Table",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 9,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 105,
      "y": 101,
      "width": 126,
      "height": 9
    },
    "bbox": [
      105,
      101,
      231,
      110
    ],
    "page_number": 9,
    "lines": 1,
    "index": 102
  },
  {
    "text": "The class-specific results show uniform struggles. Class 2 was the most challenging category to classify for the ma-",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 303,
      "y": 105,
      "width": 250,
      "height": 21
    },
    "bbox": [
      303,
      105,
      553,
      126
    ],
    "page_number": 9,
    "lines": 2,
    "style_optimization": {
      "optimized": true,
      "single_style": true,
      "style_occurrences": 2,
      "original_styles_count": 2
    },
    "consolidation_info": {
      "original_lines_count": 2,
      "original_spans_count": 2,
      "consolidated": true,
      "styles_optimized": true
    },
    "index": 103
  },
  {
    "text": "ModelAccuracy",
    "styles_used": [
      {
        "font": "CMBX10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 103,
      "y": 124,
      "width": 31,
      "height": 10
    },
    "bbox": [
      103,
      124,
      134,
      134
    ],
    "page_number": 9,
    "lines": 1,
    "index": 104
  },
  {
    "text": "jority of models, registering the lowest F1-scores, partic- Logistic Regression51.3359614542269 ularly significant for Logistic Regression (0.27) and SVM SVM Linear52.84713096802452Linear (0.35). Even leading models had relatively lower SVM Polynomial57.57774857643452 (but still high) F1-scores for Class 2 (Random Forest: 0.84, SVM RBF65.44021024967148 Decision Tree: 0.79) than the other classes. Class 4 was Random Forest Classifier89.09329829172142 typically the highest-performing class, recording F1-scores Decision Tree Classifier0.8661848445028472 of as high as 0.95 with the Random Forest model.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 64,
      "y": 128,
      "width": 489,
      "height": 82
    },
    "bbox": [
      64,
      128,
      553,
      210
    ],
    "page_number": 9,
    "index": 105
  },
  {
    "text": "VI.DiscussionIn general, empirical data strongly demonstrates that",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 121,
      "y": 219,
      "width": 18,
      "height": 11
    },
    "bbox": [
      121,
      219,
      139,
      230
    ],
    "page_number": 9,
    "lines": 1,
    "index": 106
  },
  {
    "text": "the tree-structure-based classifiers, namely Random For- est, yield the optimal solution to this classification task The performance of six different classification algo- with improved accuracy and efficient management of class rithms was compared to assess their performance on the imbalance compared to the examined linear and SVM ap- given dataset. The performance metrics like precision, re- call, F1-score, and support for each class as well as macroproaches. and weighted averages are presented in Tables I to VI.",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 230,
      "width": 510,
      "height": 74
    },
    "bbox": [
      43,
      230,
      553,
      304
    ],
    "page_number": 9,
    "index": 107
  },
  {
    "text": "VII.Conclusion",
    "styles_used": [
      {
        "font": "CMCSC10",
        "size": 12,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 375,
      "y": 300,
      "width": 24,
      "height": 12
    },
    "bbox": [
      375,
      300,
      399,
      312
    ],
    "page_number": 9,
    "lines": 1,
    "index": 108
  },
  {
    "text": "A comparative analysis reports significant difference in predictive performance between the models under con- The primary objective of this research was to develop sideration. Of special interest, tree-structure-based algo- a packaged food labeling model capable of assigning nutri- rithms showed significantly improved performance. Thetion scores ranging from A to E based on a product\u2019s ingre- Random Forest (Table V) had the highest performance dient composition. To achieve this, machine learning algo- level with a weighted average F1-score of 0.89 corrobo- rithms \u2014 specifically, Random Forest Classifier and Linear rated by a macro average F1-score of 0.88. Likewise, the Regression \u2014 were employed and evaluated side by side Decision Tree classifier (Table VI) had impressive perfor- for their effectiveness. Experimental results indicate that mance, with weighted and macro average F1-scores of 0.87both models perform comparably well on smaller datasets and 0.85, respectively. These results affirm that ensemble (ranging from 500 to 700 records), demonstrating reliable methods and decision tree structures are most appropriate classification capabilities even with limited data. This re- to identify the inherent patterns inherent in this dataset.inforces the potential of machine learning as a practical Conversely, Support Vector Machine (SVM) modelstool for nutritional assessment and consumer awareness. The developed model provides a systematic approach for performed differently depending on the kernel used. The SVM using a Radial Basis Function (RBF) kernel (Tablevaluating the healthiness of packaged food items, en- IV) performed the best of the various SVM configurations, abling consumers to make informed dietary choices. By clearly labeling products based on nutritional quality, the with a weighted average F1-score of 0.66. Then, the Poly- nomial kernel SVM (Table III) performed at a weightedsystem encourages healthier consumption habits and can serve as a valuable aid in promoting public health. Future average F1-score of 0.58.The Linear kernel SVM (Ta- ble II) and the Logistic Regression model (Table I) werework involves expanding the dataset from approximately the poorest level of performance, with weighted average700 to over 2000 entries to enhance the model\u2019s accuracy and generalizability.Furthermore, deploying the model F1-scores of 0.54 and 0.51, respectively.The relatively lower efficiency of linear models and standard SVM ker-as a web-based or mobile application can significantly im- prove its accessibility and usability, allowing users to ef- nels indicates that the data contains potential non-linear complexities that these techniques appear not to capturefortlessly assess products and make data-driven decisions well.to improve their nutritional well-being. The class imbalance is very severe, with a clear in-References dication from the \u2019Support\u2019 column in all tables ranging from 592 to 1472 instances per class. The top two mod- [1] Ross A.C., Caballero B., Cousins R.J., Tucker K.L. els, Random Forest and Decision Tree, were not affected ModernNutritioninHealthandDisease.Jones by the imbalance to a large degree, with a very high F1- and Bartlett Learning; Burlington, MA, USA: 2020. score being obtained consistently in all classes while show- [Google Scholar] ing negligible difference between their macro and weighted average scores. For all the remaining models, the perfor-[2] Whitney E.N., Rolfes S.R., Crowe T., Walsh A. Under- mance was sensitive to the differences in class distribution.standing Nutrition. Cengage; Melbourne, Australia: 2019. [Google Scholar] For Logistic Regression, SVM Linear, and SVM RBF, the weighted averages were marginally higher than the macro [3] Melaku Y.A., Temesgen A.M., Deribew A., Tessema 9",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 312,
      "width": 510,
      "height": 490
    },
    "bbox": [
      43,
      312,
      553,
      802
    ],
    "page_number": 9,
    "index": 109
  },
  {
    "text": "G.A., Deribe K., Sahle B.W., Abera S.F., Bekele T.,care\u20142020 for gestational diabetes mellitus\u201d: A criti- Lemma F., Amare A.T., et al. The impact of dietarycal Appraisal. Diabetes Ther. 2020;11:1639\u20131644. doi: risk factors on the burden of non-communicable dis-10.1007/s13300-020-00865-3. [DOI] [PMC free article] eases in Ethiopia: Findings from the Global Burden of[PubMed] [Google Scholar] Disease study 2013. Int. J. Behav. Nutr. Phys. Act. [8] Pray L., editor. Nutrigenomics and the Future of 2016;13:122. doi:10.1186/s12966-016-0447-x. [DOI] Nutrition:Proceedings of a Workshop. National [PMC free article] [PubMed] [Google Scholar] AcademiesPress;Washington,DC,USA:2018. [4] Popkin B.M., Adair L.S., Ng S.W. Global nutrition[PubMed] [Google Scholar] transition and the pandemic of obesity in developing [9] Jimenez-CarveloA.M.,Cuadros-Rodr\u00b4\u0131guezL. countries. Nutr. Rev. 2012;70:3\u201321 Datamining/machinelearningmethodsin [5] Mozaffarian D. Dietary and policy priorities forfoodomics.Curr.Opin.FoodSci.2021;37:76\u201382. cardiovascular disease,diabetes,and obesity:Adoi:10.1016/j.cofs.2020.09.008.[DOI][Google comprehensive review. Circulation. 2016;133:187\u2013225.Scholar] doi: 10.1161/CIRCULATIONAHA.115.018585. [DOI] [10] Taye M.M. Understanding of machine learning with [PMC free article] [PubMed] [Google Scholar] deep learning: Architectures, workflow, applications [6] Awuchi C.G., Igwe V.S., Amagwula I.O. Nutritionaland future directions. Computers. 2023;12:91. doi: diseases and nutrient toxicities:A systematic re-10.3390/computers12050091. [DOI] [Google Scholar] view of the diets and nutrition for prevention and [11] https://matplotlib.org/stable/users/index treatment. Int. J. Adv. Acad. Res. 2020;6:1\u201346. doi: 10.46654/ij.24889849.e61112. [DOI] [Google Scholar][12] https://scikit-learn.org/ [7] Goyal A., Gupta Y., Singla R., Kalra S., Tandon N.[13] https://numpy.org/doc/ American diabetes association \u201cstandards of medical [14] https://pandas.pydata.org/docs/ 10",
    "styles_used": [
      {
        "font": "CMR10",
        "size": 10,
        "color": 0,
        "font_flags": {
          "bold": false,
          "italic": false,
          "serif": true
        }
      }
    ],
    "position": {
      "x": 43,
      "y": 75,
      "width": 510,
      "height": 727
    },
    "bbox": [
      43,
      75,
      553,
      802
    ],
    "page_number": 10,
    "index": 110
  }
]